
In mathematics, it is common practice to assume a fixed set theory, usually with the axiom of choice, as a common basis. While it is a great advantage to work in one common language and share a lot of the basic constructions, the dual approach of adapting the  ``base language'' to particular mathematical domains is sometimes more concise, provides a new perspective and encourages new proof techniques which would be hard to find otherwise.
We use the word ``synthetic'' to indicate that the latter approach is used,
as it was used by Kock and Lawvere to describe developement of mathematics internal to certain categories \cite{lawvere-categorical-dynamics}, in particular toposes -- a program which dates back as far as 1967.

Already in the 70s in the same program, Anders Kock suggested to use the language of higher-order logic \cite{Church40} to describe the Zariski topos, the collection of sheaves for the Zariski topology \cite{Kock74,kockreyes}, which is the first occurence of synthetic algebraic geometry.
Kock's approach allowed for a more suggestive and geometrical description of schemes.
There is in particular a ``generic local ring'' $R$, which, as a sheaf, associates to any algebra $A$ its underlying set and, as described in \cite{kockreyes}, the projective space $\bP^n$ is then the set of lines in $R^{n+1}$.

Just using category theory is not the same as reasoning synthetically -- for the latter the goal is usually to derive results exclusively in one system,
as Kock and Lawvere did with differential geometry in his work.
The distinction with just using an abstraction like categories is important, since the translation from the synthetic language and back can become cumbersome -- although it is still the goal to derive statements about ordinary mathematical objects in the end.

Starting with Kock and Lawvere's work, more differential geometry was developed synthetically \cite{kock-sdg} along with a study of the models of the theory \cite{moerdijk-reyes}.
One basic axiom of the theory, called the Kock-Lawvere axiom, allows for reasoning with nilpotent infinitesimals. Our version of synthetic algebraic geometry use a generalisation of this axiom called the duality axiom. Let us now describe the Kock-Lawvere axiom.

The Kock-Lawvere axiom is added to a basic language which can be interpreted in good enough categories (for example toposes), more precisely we need basic objects like $\emptyset$, $\{\ast\}$ and $\N$ as well natural constructions like $A\times B$ or $A^B$ for objects $A$, $B$, which all behave as expected. We also need predicates $P(x)$ for elements $x:A$ so we can form subobjects like $\{x:A\mid P(x)\}$.
In this language, we assume there is a fixed ring $R$, which can be thought of as the real numbers. We define $\D(1)=\{x\in R\mid x^2=0\}$ to be the set of all square-zero elements of $R$, then the Kock-Lawvere axiom gives us a bijection
\[ e : R \times R  \to R^{\D(1)} \]
which commutes with evaluation at $0$ and projection to the first factor.
The intuition is that $\D(1)$ is so small that any function on it is linear and therefore determined by its value and its derivative at $0\in\D(1)$.
With this axiom, the derivative at $0:R$ of a function $f : R \to R$ may then be defined as $\pi_2(e^{-1}(f_{\vert \D(1)}))$. This is the start of a convenient development of differential calculus, which doesn't require any further structures on $R$ or other objects. This is the core of the synthetic method: we can work with these differential spaces as if they were sets.

To give an example, the tangent bundle of a manifold $M$ can be defined as $M^{\D(1)}$ and vector fields as sections of the map $M^{\D(1)}\to M$ evaluating at $0$. Then it is easy to see that a vector field is the same as a map $\zeta:\D(1)\to M^M$ with $\zeta(0)=\id_M$, which can be interpreted as an infinitesimal transformation of the identity map. This style of reasoning with spaces as if they were sets is also central in current synthetic algebraic geometry. 

The Kock-Lawvere axiom above and many of the axioms used in synthetic reasoning are incompatible with the law of excluded middle (LEM) and therefore also with the axiom of choice (AC). Indeed they tend to imply all maps are well-behaved (for example all maps are differentiable in the case of the Kock-Lawvere axiom), which contradicts LEM. It is however a recurring phenomenon that restricted versions of LEM and AC are compatible with synthetic languages. A very basic example is that equality of natural numbers is decidable, meaning that two natural numbers are either equal or not equal. 

%TODO: Hugo is here in the rereading

The use of nilpotent elements to capture infinitesimal quantities as mentioned above was inspired by the Grothendieck school of algebraic geometry and Anders Kock also worked with an extended axiom \cite{Kock74,kockreyes} suitable for synthetic algebraic geometry, where the role of $\D(1)$ above can be taken by any finitely presented affine scheme. In 2017 Ingo Blechschmidt finished his doctoral thesis in which he noticed a property holding internally in the Zariski-topos, which he called synthetic quasi-coherence -- this was a more general and internal version of what Kock used. In 2018, David Jaz Myers\footnote{Myers' never published on the subject, but communicated his ideas to Felix Cherubini and in talks to a larger audience \cite{myers-talk1,myers-talk2}.} started to work with a specialization of Blechschmidt's synthetic quasi-coherence and used homotopy type theory as a base language, which is the standard in synthetic algebraic geometry now and we will highlight some implications below. Myers' specialized axiom is what we now call \emph{duality axiom}.

To state the duality axiom we need the general concept behind the space $\D(1)$, which is spaces that are the common zeros of some system of polynomial equations over $R$. Such a system can be encoded representation independent by a finitely presented $R$-algebra, i.e.\ an $R$-algebra $A$ which is of the form $R[X_1,\dots,X_n]/(P_1,\dots,P_l)$ for some numbers $n,l$ and polynomials $P_i\in R[X_1,\dots,X_n]$.
Then the zero set of the system is given by the type $\Hom_{\Alg{R}}(A,R)$ of $R$-algebra homomorphisms from $A$ to the base ring, which we denote by $\Spec A$.
Now the duality axiom states that $\Spec$ is the inverse to exponentiating with $R$, i.e.\ for all 
finitely presented $R$-algebras $A$ the following is an isomorphism:
\[ (a\mapsto (\varphi\mapsto \varphi(a))) : A\to R^{\Spec A}\rlap{.}\]

Using homotopy type theory as a language for synthetic algebraic geometry is, in addition to convenience, also a language for synthetic homotopy theory.
So instead of the usual practice in algebraic topology to provide model spaces using point-set topology, one can start directly at the level of homotopy types and instead of implementing their higher structure with Kan complexes, there are rules which do not mention any implementation.
The rules of homotopy type theory allow to work with the basic objects of the theory, types, in very much the same way as one would work with sets in traditional mathematics -- with the clear exception of the law of excluded middle and the axiom of choice - although the former and restricted versions of the latter can be assumed.
Both can be seen as stating something about the spatial structure. The law of excluded middle allows us to find a complement of each subset of a given set A, which exposes A as a coproduct.
This is not true in topology, for example, $\R$ is not the coproduct of the topological subspaces $\{0\}$ and $\R/\{0\}$.
The axiom of choice states that any surjection has a section. This is also not true in topology and would trivialize all cohomology.
Thus, constructive reasoning in the sense of not using these two axioms is a necessity if we want to use spatial collections in the same way we use sets.
In synthetic algebraic geometry, we work inside homotopy type theory and remind readers of this by using the notation $x:X$ which can often be thought of as $x\in X$.
\cite{shulman-logic-of-spaces} is a more detailed introduction to homotopy type theory for a general mathematical audience.


One of the main advantages of using specifically homotopy type theory and not a different internal language,
is that it is possible to make cohomological computations, using homotopy type theory for synthetic homotopical reasoning.
This means that we are mixing two synthetic approaches, combining their advantages,
which rests on the possibility of interpreting homotopy type theory in higher toposes \cite{shulman2019all} and not just the higher topos of $\infty$-groupoids.
The general idea of using homotopy type theory to combine some kind of synthetic, spatial reasoning with synthetic homotopy theory, goes back at least to 2014, to Mike Shulman and Urs Schreiber \cite{Schreiber_2014}.
Schreiber suggested to the HoTT community at various occasions to make use of HoTT as the internal language of higher toposes, where specifities of the topos are accessed in the language via modalities.
This approach was shown to be quite effective and intuitive in Shulman's \cite{shulman-Brouwer-fixed-point} work on mixing synthetic homotopy theory in the form of HoTT and a synthetic approach to topology using a triple of modalities -- a structure called cohesion by Lawvere \cite{Lawvere2007}.

One of Schreiber's motivation was to make use of the modern perspective on cohomology, which in a higher topos can be realized as the connected components of a space of maps. This can be mimicked in HoTT, like follows: Let $X$ be a type and $A$ an abelian group and $n:\N$, then
\[ H^n(X,A):=\| X\to K(A,n) \|_0\]
is the $n$-th cohomology group of $X$ with coefficients in $A$, where $\|\_\|_0$ is the $0$-truncation, an operation which turns a type with possibly non-trivial higher identity types into a set -- a type with trivial higher structure. The type $K(A,n)$ is the $n$-th Eilenberg MacLane space, which can always be constructed for any abelian group $A$ and comes with an isomorphism $\Omega^n(K(A,n))\simeq A$.
This definition of cohomology groups allows using the synthetic homotopy theory to reason about cohomology, which had been already done successfully at the time for the cohomology of homotopy types, like spheres and finite CW-complexes, but works as well to study $0$-types.
While this internal version of cohomology does not agree with the external version mentioned above --
even the type is wrong; it is a sheaf of groups instead of a single one and, indexed by an internal natural number instead of an external one -- internal cohomology turned out to be quite useful in practice.

In 2022, trying to use this approach to calculate cohomology groups in synthetic algebraic geometry led to the discovery of what is now called Zariski-local choice \cite{draft},
which is an additional axiom that holds in the higher Zariski-topos.
It is a weakening of the axiom of choice which can be formulated as: For any surjective map $f:X\to Y$, there exists a section, i.e.\ a map $s:Y\to X$ such that $f\circ s=\id_Y$.
Zariski-local choice also states the existence of a section, but only Zariski-local and only for surjections into an affine scheme: For any surjection $f:E\to \Spec A$,
there exists a Zariski-cover $U_1,\dots,U_n$ of $\Spec A$ and maps $s_i:U_i\to E$ such that $f(s_i(x))=x$ for all $x\in U_i$.

In homotopy type theory, we use the propositional truncation $\|\_\|$ to define surjections and more generally what we mean with ``exists''.
Propositional truncation turns an arbitrary type $A$ into a type $\|A\|$ with the property $x=y$ for all $x,y:\|A\|$.
Types with this property are called propositions or (-1)-types in homotopy type theory.
Using a univalent universe of types $\mathcal U$ we have that surjection into a type $A$ are the same as type families $F:A\to \mathcal U$, such that we have $\|F(x)\|$ for all $x: A$.
Using type families instead of maps allows us to drop the condition that the maps we get are sections, since we can express it using dependent function types and we arrive at the formulation of Zariski-local choice given below in the list of axioms.
In this instance and many others, homotopy type theory provides a lot of convenience when working very formally, which is an advantage in formalization of synthetic algebraic geometry.

In total, apart from homotopy type theory and a fixed commutative ring $R$ we use in synthetic algebraic geometry the following three axioms -- we will provide some explanation for the first one below:

\begin{center}
\begin{axiom}[Locality]%
  \label{loc-axiom}
  $R$ is a local ring, i.e.\ $1\neq 0$ and whenever $x+y$ is invertible $x$ is invertible or $y$ is invertible.
\end{axiom}

\begin{axiom}[Duality]%
  \label{duality-axiom}
  For any finitely presented $R$-algebra $A$, the homomorphism
  \[ a \mapsto (\varphi\mapsto \varphi(a)) : A \to (\Spec A \to R)\]
  is an isomorphism of $R$-algebras.
\end{axiom}

\begin{axiom}[Zariski-local choice]%
  \label{Z-choice-axiom}
  Let $A$ be a finitely presented $R$-algebra
  and let $B : \Spec A \to \mU$ be a family of inhabited types.
  Then there exists a Zariski-cover $U_1,\dots,U_n\subseteq \Spec A$
  together with dependent functions $s_i : (x : U_i)\to B(x)$.
\end{axiom}
\end{center}

With the Kock-Lawvere axiom, we introduced the first historic predecessor of the duality axiom as a starting point for convenient infinitesimal computations,
while this is also possible in synthetic algebraic geometry, the general duality axiom has a lot of surprising consequences.
In line with classical algebraic geometry, it shows that we have the usual anti-equivalence between finitely presented $R$-algebras and affine schemes of finite presentation over $R$.
What is more surprising, is the consequence that all functions $R\to R$ are polynomials and that it has implications on the properties of the base ring $R$.
For example, for all $x:R$, $x$ is invertible if and only if we have $x\neq 0$.
Duality also implies that affine schemes can only have bounded maps to the natural numbers.

Surprisingly, the Zariski-local choice axiom was also usable to solve problems which have no obvious connection to cohomology.
For example, it admits a proof that pointwise open subsets of an affine scheme are the same as subsets which are given by unions of non-vanishing sets of functions on the scheme.
In more detail, we say a proposition $P$ is open, if there are a natural number $n$ and elements $r_1,\dots,r_n$ of the base ring $R$,
such that $P$ is equivalent to the proposition $r_1\neq 0 \vee\dots\vee r_n\neq 0$.
Then we call a subset $U$ of a type $X$ open, if the proposition $x\in U$ is open for all $x:X$.
Using Zariski-local choice, these pointwise existing ring elements can be turned into locally existing functions.
For an affine scheme $X$ it is even the case, that an open subset in the pointwise sense, is a union of non-vanishing sets $D(f_i)$ of global functions $f_i:\Spec A \to R$.
An analogous result holds also for closed propositions, which are propositions of the form $r_1=0\wedge\dots\wedge r_n=0$ for $r_i:R$ and vanishing sets of functions on affine schemes.

The connection between pointwise and local openness is important to make the synthetic definition of a scheme work well:
A scheme is a type $X$, that merely has a finite open cover by affine schemes.
To produce interesting examples, it is necessary to use the locality axiom.
This is related to the Zariski topology and ensures that classical examples of Zariski covers can be reproduced.
One central example is projective space, which can be defined as the quotient of $R^{n+1}/\{0\}$ by the action of $R^\times$ by scaling.
A cover of this type is given by sets of equivalence classes of the form $\{[x_0:\cdots:x_n] \vert x_i\neq 0 \}$, which is clearly open by the pointwise definition.
To see that it is a cover, one has to note that for $x:R^{n+1}$, $x\neq 0$ is equivalent to one of the entries $x_i$ being different from 0. In synthetic algebraic geometry, this is the case for the base ring $R$ and the proof uses that $R$ is a local ring.
